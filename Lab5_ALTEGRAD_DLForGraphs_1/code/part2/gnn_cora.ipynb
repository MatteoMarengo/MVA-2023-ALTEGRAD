{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Deep Learning on Graphs - ALTEGRAD - Nov 2023\n",
    "MARENGO Matteo\n",
    "matteo.marengo@ens-paris-saclay.fr\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from utils import load_cora, normalize_adjacency, sparse_to_torch_sparse\n",
    "from models import GNN\n",
    "\n",
    "# Initialize device\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# Hyperparameters\n",
    "epochs = 100\n",
    "n_hidden_1 = 64\n",
    "n_hidden_2 = 32\n",
    "learning_rate = 0.01\n",
    "dropout_rate = 0.5\n",
    "\n",
    "# Read data\n",
    "features, adj, class_labels = load_cora()\n",
    "n = adj.shape[0] # Number of nodes\n",
    "n_class = np.unique(class_labels).size # Number of classes\n",
    "\n",
    "adj = normalize_adjacency(adj) # Normalize adjacency matrix\n",
    "\n",
    "# Yields indices to split data into training, validation and test sets\n",
    "idx = np.random.permutation(n)\n",
    "idx_train = idx[:int(0.6*n)]\n",
    "idx_val = idx[int(0.6*n):int(0.8*n)]\n",
    "idx_test = idx[int(0.8*n):]\n",
    "\n",
    "# Transform the numpy matrices/vectors to torch tensors\n",
    "features = torch.FloatTensor(features).to(device)\n",
    "y = torch.LongTensor(class_labels).to(device)\n",
    "adj = sparse_to_torch_sparse(adj).to(device)\n",
    "idx_train = torch.LongTensor(idx_train).to(device)\n",
    "idx_val = torch.LongTensor(idx_val).to(device)\n",
    "idx_test = torch.LongTensor(idx_test).to(device)\n",
    "\n",
    "# Creates the model and specifies the optimizer\n",
    "model = GNN(features.shape[1], n_hidden_1, n_hidden_2, n_class, dropout_rate).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    t = time.time()\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output,_ = model(features, adj)\n",
    "    loss_train = F.nll_loss(output[idx_train], y[idx_train])\n",
    "    acc_train = accuracy_score(torch.argmax(output[idx_train], dim=1).detach().cpu().numpy(), y[idx_train].cpu().numpy())\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    \n",
    "    model.eval()\n",
    "    output,_ = model(features, adj)\n",
    "\n",
    "    loss_val = F.nll_loss(output[idx_val], y[idx_val])\n",
    "    acc_val = accuracy_score(torch.argmax(output[idx_val], dim=1).detach().cpu().numpy(), y[idx_val].cpu().numpy())\n",
    "    print('Epoch: {:03d}'.format(epoch+1),\n",
    "          'loss_train: {:.4f}'.format(loss_train.item()),\n",
    "          'acc_train: {:.4f}'.format(acc_train),\n",
    "          'loss_val: {:.4f}'.format(loss_val.item()),\n",
    "          'acc_val: {:.4f}'.format(acc_val),\n",
    "          'time: {:.4f}s'.format(time.time() - t))\n",
    "\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    output, embeddings = model(features, adj)\n",
    "    loss_test = F.nll_loss(output[idx_test], y[idx_test])\n",
    "    acc_test = accuracy_score(torch.argmax(output[idx_test], dim=1).detach().cpu().numpy(), y[idx_test].cpu().numpy())\n",
    "    \n",
    "    print(\"Test set results:\",\n",
    "          \"loss= {:.4f}\".format(loss_test.item()),\n",
    "          \"accuracy= {:.4f}\".format(acc_test))\n",
    "\n",
    "    return embeddings[idx_test]\n",
    "\n",
    "\n",
    "# Train model\n",
    "t_total = time.time()\n",
    "for epoch in range(epochs):\n",
    "    train(epoch)\n",
    "print(\"Optimization Finished!\")\n",
    "print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
    "print()\n",
    "\n",
    "# Testing\n",
    "embeddings_test = test()\n",
    "\n",
    "\n",
    "\n",
    "############## Task 13\n",
    "# Transforms torch tensor to numpy matrix\n",
    "\n",
    "##################\n",
    "# your code here #\n",
    "##################\n",
    "\n",
    "\n",
    "# Projects the emerging representations to two dimensions using t-SNE\n",
    "\n",
    "##################\n",
    "# your code here #\n",
    "##################\n",
    "\n",
    "\n",
    "labels = class_labels[idx_test]\n",
    "unique_labels = np.unique(labels)\n",
    "\n",
    "colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for i in range(unique_labels.size):\n",
    "    idxs = [j for j in range(labels.size) if labels[j]==unique_labels[i]]\n",
    "    ax.scatter(embeddings_test_2d[idxs,0], \n",
    "               embeddings_test_2d[idxs,1], \n",
    "               c=colors[i],\n",
    "               label=i,\n",
    "               alpha=0.7,\n",
    "               s=10)\n",
    "\n",
    "ax.legend(scatterpoints=1)\n",
    "fig.suptitle('T-SNE Visualization of the nodes of the test set',fontsize=12)\n",
    "fig.set_size_inches(15,9)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
